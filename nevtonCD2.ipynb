{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Nevton de Castro\n",
    "\n",
    "Nome: Omar Dibo\n",
    "\n",
    "Nome: Laura Perim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from random import shuffle\n",
    "import threading "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@Devsegundoseme1***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'auth.pass'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-57fcf65e8147>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#leitura do arquivo no formato JSON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'auth.pass'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'auth.pass'"
     ]
    }
   ],
   "source": [
    "#Dados de autenticação do twitter: authpass\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @Devsegundoseme1\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:   \n",
    "    data = json.load(fp)\n",
    "    \n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'civic'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 750\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 500\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    if msg.full_text.lower()[0] != 'r' and msg.full_text.lower()[1] != 't' and msg.full_text.lower()[2] != ' ':\n",
    "        msgs.append(msg.full_text.lower())\n",
    "        i += 1\n",
    "        if i > n:\n",
    "                break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'produto' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c952be8eb010>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Verifica se o arquivo não existe para não substituir um conjunto pronto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./{0}.xlsx'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproduto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#Abre o arquivo para escrita\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExcelWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{0}.xlsx'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproduto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'produto' is not defined"
     ]
    }
   ],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs1[:n])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs1[n:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic = pd.read_excel('civic.xlsx')\n",
    "spm1 = civic[civic.valor==0] #tweets de spam ou venda\n",
    "irr1 = civic[civic.valor==1] #tweets irrelevantes\n",
    "rel1 = civic[civic.valor==2] #tweets de elogios ou criticas\n",
    "irr = irr1['Treinamento'].tolist()\n",
    "rel = rel1['Treinamento'].tolist()\n",
    "spm = spm1['Treinamento'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    538\n",
       "Name: valor, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm1.valor.value_counts() #40\n",
    "rel1.valor.value_counts() #172\n",
    "irr1.valor.value_counts() #538"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "o          0.035815\n",
       "um         0.027767\n",
       "de         0.023340\n",
       "e          0.022938\n",
       "que        0.022938\n",
       "meu        0.018109\n",
       "é          0.017706\n",
       "honda      0.017706\n",
       "do         0.013280\n",
       "https      0.011670\n",
       "//t        0.011670\n",
       "eu         0.010463\n",
       "a          0.009658\n",
       "pra        0.008853\n",
       "carro      0.008853\n",
       "na         0.008853\n",
       "mais       0.008451\n",
       "não        0.008048\n",
       "com        0.007646\n",
       "corolla    0.007646\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nop = []\n",
    "#nao vamos remover \"#\" nem \"|\"\n",
    "for i in rel:\n",
    "    punctuation = '[!\\-.:?;,_+]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', i.lower())\n",
    "    nop.append(text_subbed)\n",
    "\n",
    "\n",
    "clean = []\n",
    "for i in nop:     \n",
    "    trash = 'civic'\n",
    "    text_subbed = re.sub(trash, ' ', i)\n",
    "    clean.append(text_subbed)\n",
    "\n",
    "relfinal = []\n",
    "for i in clean:\n",
    "    e = pd.Series(i.split())\n",
    "    for i in e:\n",
    "        relfinal.append(i)\n",
    "df = pd.DataFrame(relfinal)\n",
    "reldata = df[0].value_counts(True)\n",
    "reldata.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "um       0.026008\n",
       "de       0.024934\n",
       "o        0.024099\n",
       "e        0.021355\n",
       "que      0.021236\n",
       "a        0.018850\n",
       "do       0.017060\n",
       "honda    0.015867\n",
       "//t      0.015867\n",
       "https    0.015867\n",
       "no       0.011095\n",
       "eu       0.011095\n",
       "meu      0.010021\n",
       "na       0.009186\n",
       "com      0.009186\n",
       "é        0.008948\n",
       "não      0.008590\n",
       "mais     0.007277\n",
       "carro    0.007158\n",
       "pra      0.006442\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nop2 = []\n",
    "for i in irr:     \n",
    "    punctuation = '[!\\-.:?;,_\\+]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', i.lower())\n",
    "    nop2.append(text_subbed)\n",
    "\n",
    "\n",
    "clean2 = []\n",
    "for i in nop2:     \n",
    "    trash = 'civic'\n",
    "    text_subbed = re.sub(trash, ' ', i)\n",
    "    clean2.append(text_subbed)\n",
    "\n",
    "\n",
    "relfinal2 = []\n",
    "for i in clean2:\n",
    "    e = pd.Series(i.split())\n",
    "    for i in e:\n",
    "        relfinal2.append(i)\n",
    "df2 = pd.DataFrame(relfinal2)\n",
    "irrdata = df2[0].value_counts(True)\n",
    "irrdata.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03492063492063492"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nop3 = []\n",
    "#nao vamos remover \"#\" nem \"|\"\n",
    "for i in spm:     \n",
    "    punctuation = '[!\\-.:?;,_\\+]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', i.lower())\n",
    "    nop3.append(text_subbed)\n",
    "\n",
    "clean3 = []\n",
    "for i in nop3:     \n",
    "    trash = 'civic'\n",
    "    text_subbed = re.sub(trash, ' ', i)\n",
    "    clean3.append(text_subbed)\n",
    "\n",
    "relfinal3 = []\n",
    "for i in clean3:\n",
    "    e = pd.Series(i.split())\n",
    "    for i in e:\n",
    "        relfinal3.append(i)\n",
    "df3 = pd.DataFrame(relfinal3)\n",
    "spmdata = df3[0].value_counts(True)\n",
    "spmdata['https']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f']\n",
      "['e', 'r', 't', 'y', 'u', 'i']\n"
     ]
    }
   ],
   "source": [
    "l=['a','b','c','d','e','f']\n",
    "t=['e','r','t','y','u','i']\n",
    "for i in l, t:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2485\n",
      "8382\n",
      "1260\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k = []\n",
    "oi = civic['Treinamento'].tolist()\n",
    "\n",
    "for i in oi:\n",
    "    \n",
    "    \n",
    "    s = i.split()\n",
    "    \n",
    "    for t in s:\n",
    "        \n",
    "        k.append(i)\n",
    "\n",
    "a = list(set(k))\n",
    "td = len(a)\n",
    "\n",
    "k=[]\n",
    "for i in clean:\n",
    "    s = i.split()\n",
    "    for t in s:\n",
    "        k.append(i)\n",
    "        \n",
    "tdrel = len(k)\n",
    "\n",
    "k=[]\n",
    "for i in clean2:\n",
    "    s = i.split()\n",
    "    for t in s:\n",
    "        k.append(i)\n",
    "        \n",
    "tdirr = len(k)\n",
    "\n",
    "k=[]\n",
    "for i in clean3:\n",
    "    s = i.split()\n",
    "    for t in s:\n",
    "        k.append(i)\n",
    "        \n",
    "tdspm = len(k)\n",
    "print(tdrel)\n",
    "print(tdirr)\n",
    "print(tdspm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista =[]\n",
    "d=-1\n",
    "for i in clean:\n",
    "    t=1\n",
    "    \n",
    "    e = pd.Series(i.split())\n",
    "    \n",
    "    for w in e:\n",
    "        \n",
    "        if w in df[0].tolist():\n",
    "            r=reldata[w]\n",
    "        else:\n",
    "            r=0\n",
    "        t = r*t\n",
    "    t*(172/750)\n",
    "    o=[]\n",
    "    o.append(t)\n",
    "    lista.append(o)\n",
    "    \n",
    "d = -1\n",
    "for i in clean:\n",
    "    t =1\n",
    "    d =d+1\n",
    "    e = pd.Series(i.split())\n",
    "    for w in e:\n",
    "        if w in df2[0].tolist():\n",
    "            r = irrdata[w]\n",
    "        else:\n",
    "            r=0\n",
    "        t = r*t\n",
    "    t*(538/750)\n",
    "    lista[d].append(t)\n",
    "    \n",
    "d = -1\n",
    "for i in clean:\n",
    "    t =1\n",
    "    d =d+1\n",
    "    e = pd.Series(i.split())\n",
    "    for w in e:\n",
    "        if w in df3[0].tolist():\n",
    "            r = spmdata[w]\n",
    "        else:\n",
    "            r=0\n",
    "        t = r*t\n",
    "    t*(40/750)\n",
    "    lista[d].append(t)\n",
    "qual=[]\n",
    "m=-1\n",
    "for i in lista:\n",
    "    m=m+1\n",
    "    if (lista[m][0] > lista[m][1]) and (lista[m][0] > lista[m][2]):\n",
    "        qual.append('relevante')\n",
    "    if (lista[m][1] > lista[m][0]) and (lista[m][1] > lista[m][2]):\n",
    "        qual.append('irrelevante')\n",
    "    if (lista[m][2] > lista[m][0]) and (lista[m][2] > lista[m][1]):\n",
    "        qual.append('spam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista =[]\n",
    "\n",
    "d=-1\n",
    "for i in clean2:\n",
    "    t=1\n",
    "    \n",
    "    e = pd.Series(i.split())\n",
    "    \n",
    "    for w in e:\n",
    "        \n",
    "        if w in df[0].tolist():\n",
    "            r=reldata[w]\n",
    "        else:\n",
    "            r=0\n",
    "        t = r*t\n",
    "    t*(172/750)\n",
    "    o=[]\n",
    "    o.append(t)\n",
    "    lista.append(o)\n",
    "\n",
    "\n",
    "d = -1\n",
    "for i in clean2:\n",
    "    t =1\n",
    "    d =d+1\n",
    "    e = pd.Series(i.split())\n",
    "    for w in e:\n",
    "        if w in df2[0].tolist():\n",
    "            r = irrdata[w]\n",
    "        else:\n",
    "            r=0\n",
    "        t = r*t\n",
    "    t*(538/750)\n",
    "    lista[d].append(t)\n",
    "    \n",
    "d = -1\n",
    "for i in clean2:\n",
    "    t =1\n",
    "    d =d+1\n",
    "    e = pd.Series(i.split())\n",
    "    for w in e:\n",
    "        if w in df3[0].tolist():\n",
    "            r = spmdata[w]\n",
    "        else:\n",
    "            r=0\n",
    "        t = r*t\n",
    "    t*(40/750)\n",
    "    lista[d].append(t)\n",
    "qual=[]\n",
    "m=-1\n",
    "for i in lista:\n",
    "    m=m+1\n",
    "    if (lista[m][0] > lista[m][1]) and (lista[m][0] > lista[m][2]):\n",
    "        qual.append('relevante')\n",
    "    if (lista[m][1] > lista[m][0]) and (lista[m][1] > lista[m][2]):\n",
    "        qual.append('irrelevante')\n",
    "    if (lista[m][2] > lista[m][0]) and (lista[m][2] > lista[m][1]):\n",
    "        qual.append('spam')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista =[]\n",
    "\n",
    "d=-1\n",
    "for i in clean3:\n",
    "    t=1\n",
    "    \n",
    "    e = pd.Series(i.split())\n",
    "    \n",
    "    for w in e:\n",
    "        \n",
    "        if w in df[0].tolist():\n",
    "            r=reldata[w]\n",
    "        else:\n",
    "            r=0\n",
    "        t = r*t\n",
    "    t*(172/750)\n",
    "    o=[]\n",
    "    o.append(t)\n",
    "    lista.append(o)\n",
    "\n",
    "\n",
    "d = -1\n",
    "for i in clean3:\n",
    "    t =1\n",
    "    d =d+1\n",
    "    e = pd.Series(i.split())\n",
    "    for w in e:\n",
    "        if w in df2[0].tolist():\n",
    "            r = irrdata[w]\n",
    "        else:\n",
    "            r=0\n",
    "        t = r*t\n",
    "    t*(538/750)\n",
    "    lista[d].append(t)\n",
    "    \n",
    "d = -1\n",
    "for i in clean3:\n",
    "    t =1\n",
    "    d =d+1\n",
    "    e = pd.Series(i.split())\n",
    "    for w in e:\n",
    "        if w in df3[0].tolist():\n",
    "            r = spmdata[w]\n",
    "        else:\n",
    "            r=0\n",
    "        t = r*t\n",
    "    t*(40/750)\n",
    "    lista[d].append(t)\n",
    "qual=[]\n",
    "m=-1\n",
    "for i in lista:\n",
    "    m=m+1\n",
    "    if (lista[m][0] > lista[m][1]) and (lista[m][0] > lista[m][2]):\n",
    "        qual.append('relevante')\n",
    "    if (lista[m][1] > lista[m][0]) and (lista[m][1] > lista[m][2]):\n",
    "        qual.append('irrelevante')\n",
    "    if (lista[m][2] > lista[m][0]) and (lista[m][2] > lista[m][1]):\n",
    "        qual.append('spam')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "um = df[0].value_counts()\n",
    "dois = df2[0].value_counts()\n",
    "tres = df3[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(tweets):\n",
    "    lista =[]\n",
    "    \n",
    "    d=-1\n",
    "    for i in tweets:\n",
    "        t=1\n",
    "\n",
    "        e = pd.Series(i.split())\n",
    "        \n",
    "        for w in e:\n",
    "            if w in df[0].tolist():\n",
    "                r = (df[0].value_counts()[w]+1)/(tdrel + td)\n",
    "            else:\n",
    "                r = 1/(tdrel + td)\n",
    "            t = r*t\n",
    "        t*(172/750)\n",
    "        o=[]\n",
    "        o.append(t)\n",
    "        lista.append(o)\n",
    "\n",
    "\n",
    "    d = -1\n",
    "    for i in tweets:\n",
    "        t =1\n",
    "        d =d+1\n",
    "        e = pd.Series(i.split())\n",
    "        for w in e:\n",
    "            if w in df2[0].tolist():\n",
    "                r = (df2[0].value_counts()[w]+1)/(tdirr + td)\n",
    "            else:\n",
    "                r= 1/(tdirr + td)\n",
    "            t = r*t\n",
    "        t*(538/750)\n",
    "        lista[d].append(t)\n",
    "\n",
    "    d = -1\n",
    "    for i in tweets:\n",
    "        t =1\n",
    "        d =d+1\n",
    "        e = pd.Series(i.split())\n",
    "        for w in e:\n",
    "            if w in df3[0].tolist():\n",
    "                r = (df3[0].value_counts()[w]+1)/(tdspm + td)\n",
    "            else:\n",
    "                r= 1/(tdspm+td)\n",
    "            t = r*t\n",
    "        t*(40/750)\n",
    "        lista[d].append(t)\n",
    "    qual=[]\n",
    "    m=-1\n",
    "    for i in lista:\n",
    "        m=m+1\n",
    "        if (lista[m][0] > lista[m][1]) and (lista[m][0] > lista[m][2]):\n",
    "            qual.append('relevante')\n",
    "        if (lista[m][1] > lista[m][0]) and (lista[m][1] > lista[m][2]):\n",
    "            qual.append('irrelevante')\n",
    "        if (lista[m][2] > lista[m][0]) and (lista[m][2] > lista[m][1]):\n",
    "            qual.append('spam')\n",
    "    return qual\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g=0\n",
    "b=0\n",
    "erros = 0\n",
    "for i in p(clean):\n",
    "    if i != 'relevante':\n",
    "        erros = erros+1\n",
    "\n",
    "erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i in p(clean2):\n",
    "    if i != 'irrelevante':\n",
    "        erros = erros+1\n",
    "\n",
    "\n",
    "erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in p(clean3):\n",
    "    if i != 'spam':\n",
    "        erros = erros+1\n",
    "erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "p() missing 1 required positional argument: 'tweets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-b1947e98495b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtimer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Acuracia\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: p() missing 1 required positional argument: 'tweets'"
     ]
    }
   ],
   "source": [
    "\n",
    "  \n",
    "timer = threading.Timer(300.0, p()) \n",
    "timer.start() \n",
    "print(\"Acuracia\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
